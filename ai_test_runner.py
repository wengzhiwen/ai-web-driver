"""
AIé©±åŠ¨çš„Webæµ‹è¯•å·¥å…·ä¸»ç¨‹åº
æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›å®Œæ•´çš„æµ‹è¯•æ‰§è¡Œæµç¨‹
"""

import asyncio
import os
import argparse
from datetime import datetime
from typing import List, Optional

from browser_use.llm import ChatOpenAI
from dotenv import load_dotenv

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from test_parser import TestRequirementParser
from llm_analyzer import LLMTestAnalyzer
from test_executor import TestExecutionEngine
from result_analyzer import LLMResultAnalyzer
from report_generator import TestReportGenerator
from test_types import TestExecution, TestCase


class AITestRunner:
    """AIæµ‹è¯•è¿è¡Œå™¨ - ä¸»è¦çš„æµ‹è¯•å·¥å…·ç±»"""

    def __init__(self):
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()

        # åˆå§‹åŒ–LLM
        self.llm = self._init_llm()

        # åˆå§‹åŒ–ç»„ä»¶
        self.parser = TestRequirementParser()
        self.analyzer = LLMTestAnalyzer(self.llm)
        self.executor = TestExecutionEngine(self.llm, enable_screenshots=True)
        self.result_analyzer = LLMResultAnalyzer(self.llm)
        self.report_generator = TestReportGenerator(self.result_analyzer)

        print("ğŸ¤– AIé©±åŠ¨çš„Webæµ‹è¯•å·¥å…·å·²åˆå§‹åŒ–")

    def _init_llm(self) -> ChatOpenAI:
        """åˆå§‹åŒ–LLM"""
        api_key = os.getenv("API_KEY")
        base_url = os.getenv("BASE_URL")
        model = os.getenv("MODEL_STD", "glm-4-flash")

        if not api_key:
            raise ValueError("æœªæ‰¾åˆ°API_KEYç¯å¢ƒå˜é‡ï¼Œè¯·æ£€æŸ¥é…ç½®æ–‡ä»¶")

        return ChatOpenAI(model=model, api_key=api_key, base_url=base_url)

    async def run_tests_from_file(self, test_file: str, suite_name: Optional[str] = None) -> List[TestExecution]:
        """ä»æ–‡ä»¶è¿è¡Œæµ‹è¯•"""
        print(f"ğŸ“ å¼€å§‹è§£ææµ‹è¯•æ–‡ä»¶: {test_file}")

        # è§£ææµ‹è¯•éœ€æ±‚
        try:
            parsed_cases = self.parser.parse_markdown_file(test_file)
            print(f"âœ… æˆåŠŸè§£æ {len(parsed_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
        except Exception as e:
            print(f"âŒ è§£ææµ‹è¯•æ–‡ä»¶å¤±è´¥: {e}")
            return []

        if not parsed_cases:
            print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„æµ‹è¯•ç”¨ä¾‹")
            return []

        # åˆ†ææµ‹è¯•ç”¨ä¾‹
        print("ğŸ§  ä½¿ç”¨LLMåˆ†ææµ‹è¯•ç”¨ä¾‹...")
        test_cases = []
        for i, parsed_case in enumerate(parsed_cases):
            try:
                print(f"  åˆ†ææµ‹è¯•ç”¨ä¾‹ {i+1}/{len(parsed_cases)}: {parsed_case.title}")
                test_case = await self.analyzer.analyze_test_case(parsed_case)
                test_cases.append(test_case)
            except Exception as e:
                print(f"âŒ åˆ†ææµ‹è¯•ç”¨ä¾‹å¤±è´¥: {parsed_case.title} - {e}")

        if not test_cases:
            print("âŒ æ²¡æœ‰æˆåŠŸåˆ†æçš„æµ‹è¯•ç”¨ä¾‹")
            return []

        # è®¾ç½®å¥—ä»¶åç§°
        if not suite_name:
            suite_name = f"æµ‹è¯•å¥—ä»¶_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

        # æ‰§è¡Œæµ‹è¯•
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œæµ‹è¯•å¥—ä»¶: {suite_name}")
        print(f"   å…± {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")

        executions = await self.executor.execute_test_suite(test_cases)

        # åˆ†ææ‰§è¡Œç»“æœ
        print("ğŸ“Š åˆ†ææ‰§è¡Œç»“æœ...")
        for i, execution in enumerate(executions):
            try:
                # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½ç»“æœåˆ†æ
                analyzed_result = await self.result_analyzer.analyze_execution_result(execution)
                execution.result = analyzed_result

                # ç”Ÿæˆæµ‹è¯•æ‘˜è¦
                summary = await self.result_analyzer.generate_test_summary(execution)
                print(f"  æµ‹è¯•ç”¨ä¾‹ {i+1}: {execution.test_case.title}")
                print(f"    ç»“æœ: {execution.result.value}")
                print(f"    æ‘˜è¦: {summary}")
            except Exception as e:
                print(f"âš ï¸ ç»“æœåˆ†æå¤±è´¥: {e}")

        return executions

    async def run_single_test(self, test_description: str) -> TestExecution:
        """è¿è¡Œå•ä¸ªæµ‹è¯•ï¼ˆä»æè¿°ï¼‰"""
        print(f"ğŸ¯ è¿è¡Œå•ä¸ªæµ‹è¯•: {test_description}")

        # åˆ›å»ºä¸´æ—¶è§£æçš„æµ‹è¯•ç”¨ä¾‹
        from test_parser import ParsedTestCase
        from test_types import TestType
        import re

        # ä»æè¿°ä¸­æå–URL
        url_pattern = r'https?://[^\s]+'
        urls = re.findall(url_pattern, test_description)
        url = urls[0] if urls else ""

        temp_parsed = ParsedTestCase(title="ä¸´æ—¶æµ‹è¯•ç”¨ä¾‹",
                                     description=test_description,
                                     raw_content=test_description,
                                     sections={"description": test_description},
                                     metadata={
                                         "case_id": f"temp_{int(datetime.now().timestamp())}",
                                         "url": url
                                     })

        # åˆ†ææµ‹è¯•ç”¨ä¾‹
        test_case = await self.analyzer.analyze_test_case(temp_parsed)

        # æ‰§è¡Œæµ‹è¯•
        execution = await self.executor.execute_test_case(test_case)

        # åˆ†æç»“æœ
        analyzed_result = await self.result_analyzer.analyze_execution_result(execution)
        execution.result = analyzed_result

        # ç”Ÿæˆæ‘˜è¦
        summary = await self.result_analyzer.generate_test_summary(execution)
        print(f"  ç»“æœ: {execution.result.value}")
        print(f"  æ‘˜è¦: {summary}")

        return execution

    async def generate_reports(self, executions: List[TestExecution], suite_name: str = "Test Suite") -> dict:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")

        if not executions:
            print("âš ï¸ æ²¡æœ‰æµ‹è¯•æ‰§è¡Œç»“æœï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
            return {}

        try:
            # ç”Ÿæˆæ‰€æœ‰æ ¼å¼çš„æŠ¥å‘Š
            report_paths = await self.report_generator.generate_all_formats(executions, suite_name)

            print("âœ… æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå®Œæˆ:")
            for format_type, path in report_paths.items():
                print(f"  {format_type.upper()}: {path}")

            # ç”Ÿæˆå¥—ä»¶åˆ†æ
            try:
                suite_analysis = await self.result_analyzer.analyze_test_suite_results(executions)
                print(f"ğŸ“ˆ æµ‹è¯•å¥—ä»¶åˆ†æ:")
                print(f"  é€šè¿‡ç‡: {suite_analysis['summary']['pass_rate']:.1f}%")
                print(f"  æ€»è€—æ—¶: {suite_analysis['execution_time']['total']:.2f}ç§’")
            except Exception as e:
                print(f"âš ï¸ å¥—ä»¶åˆ†æå¤±è´¥: {e}")
                # æä¾›é»˜è®¤åˆ†æ
                total = len(executions)
                passed = sum(1 for e in executions if e.result.value == "passed")
                failed = sum(1 for e in executions if e.result.value == "failed")
                error = sum(1 for e in executions if e.result.value == "error")
                total_time = sum(e.total_execution_time or 0 for e in executions)
                print(f"ğŸ“ˆ æµ‹è¯•å¥—ä»¶åˆ†æ:")
                print(f"  é€šè¿‡ç‡: {(passed/total*100):.1f}%" if total > 0 else "  é€šè¿‡ç‡: 0%")
                print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")

            return report_paths

        except Exception as e:
            print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
            return {}


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AIé©±åŠ¨çš„Webæµ‹è¯•å·¥å…·")
    parser.add_argument("--file", "-f", help="æµ‹è¯•éœ€æ±‚æ–‡ä»¶è·¯å¾„ï¼ˆMarkdownæ ¼å¼ï¼‰")
    parser.add_argument("--test", "-t", help="å•ä¸ªæµ‹è¯•æè¿°")
    parser.add_argument("--suite", "-s", help="æµ‹è¯•å¥—ä»¶åç§°")
    parser.add_argument("--no-report", action="store_true", help="ä¸ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š")

    args = parser.parse_args()

    async def run():
        test_runner = AITestRunner()
        executions = []

        try:
            if args.file:
                # ä»æ–‡ä»¶è¿è¡Œæµ‹è¯•
                executions = await test_runner.run_tests_from_file(args.file, args.suite)

            elif args.test:
                # è¿è¡Œå•ä¸ªæµ‹è¯•
                execution = await test_runner.run_single_test(args.test)
                executions = [execution]

            else:
                print("âŒ è¯·æŒ‡å®šæµ‹è¯•æ–‡ä»¶æˆ–æµ‹è¯•æè¿°")
                print("ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯")
                return

            # ç”ŸæˆæŠ¥å‘Š
            if not args.no_report and executions:
                suite_name = args.suite or f"æµ‹è¯•å¥—ä»¶_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                await test_runner.generate_reports(executions, suite_name)

            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            if executions:
                total = len(executions)
                passed = sum(1 for e in executions if e.result.value == "passed")
                failed = sum(1 for e in executions if e.result.value == "failed")
                error = sum(1 for e in executions if e.result.value == "error")

                print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
                print(f"   æ€»è®¡: {total}")
                print(f"   é€šè¿‡: {passed}")
                print(f"   å¤±è´¥: {failed}")
                print(f"   é”™è¯¯: {error}")
                print(f"   é€šè¿‡ç‡: {(passed/total*100):.1f}%" if total > 0 else "   é€šè¿‡ç‡: 0%")

        except KeyboardInterrupt:
            print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(run())


if __name__ == "__main__":
    main()
